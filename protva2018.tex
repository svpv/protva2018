\documentclass[russian,a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{url}
\usepackage{fullpage}
\usepackage{comment}

\sloppy
\hyphenpenalty=666

\begin{document}
\title{\texttt{zrec}~--- формат\\метаданных репозитория}
\author{Алексей Турбин}
\date{17 сентября 2018 г.}
\maketitle

\begin{abstract}

\end{abstract}

\section{Введение}
Перед обновлением пакетов из репозитория скачивается большой файл с \textit{записями пакетов} (records);
в \verb|apt-rpm| это файлы \verb|pkglist.xz| и \verb|srclist.xz|, содержащие урезанные
rpm-заголовки (в \verb|repomd|-репозиториях записями можно считать сегменты XML-файла).
Файл \verb|pkglist.xz| хорошо сжат, но распаковка его занимает несколько секунд, и далее
он хранится в \verb|/var/lib/apt| в разжатом виде, занимая довольно много места (200--300 Мб;
здесь не столько жалко места на диске, сколь возникают <<тормоза>> при доступе к файлу).
Пережать же в более <<легкий>> формат \verb|pkglist| нельзя, поскольку \verb|apt| требует произвольный
доступ к записям (команда \texttt{apt-cache show} делает \verb|lseek(2)| и считывает запись).

В 2017 г.~автор предпринял попытку разработать <<легкий>> формат \verb|zpkglist|
для сжатия записей после скачивания \cite{zpkglist}.
За основу была взята библиотека сжатия \verb|LZ4|; для нее была адаптирована техника сжатия со словарем,
реализованная в библиотеке \verb|zstd|.  Перед сжатием записи группировались по 4 штуки, что значительно
улучшало коэффициент сжатия, однако произвольный доступ требовал распаковки группы из четырех записей.

В мае 2018 г.~Джонатан Дайетер (Jonathan Dieter) анонсировал похожий проект \verb|zchunk| \cite{dieter}
(формат файла и библиотека сжатия).  Поддержка \verb|zchunk| добавлена в \verb|dnf|, планируется к использованию
в Fedora~29 либо Fedora~30.  \verb|zchunk| основывается на алгоритме \verb|zstd|, который способен, в отличие от \verb|LZ4|,
обеспечить значительно более высокий, <<релизный>> уровень сжатия (хотя и несколько не дотягивает до \verb|xz|).
Поэтому интерес автора стал смещаться в сторону использования нового формата для сжатия на сервере (сжатый файл
не требует распаковки на клиенте).

Файл в формате \verb|zchunk| можно понимать просто как сжатый поток байтов.  При сжатии поток нарезается на куски (chunking)
и каждый кусок сжимается хотя и отдельно, но \textit{со словарем}, отдельно хранящемся в файле (что значительно улучшает
коэффициент сжатия).  Естественно, при сжатии записей нарезка идет по границам записей, но в одном куске может содержаться
и несколько записей.  В начале же файла хранится \textit{индекс} кусков: их размеры и хеш-суммы.  Наличие индекса делает
возможным \textit{синхронизацию}: клиент сначала скачивает индекс и потом~--- через HTTP range requests~--- недостающие
куски, перестраивая старый файл в новый.

Формат \verb|zchunk| не устраивает автора лишь в деталях.  Далее рассмотрены некоторые специальные особенности сжатия
и синхронизации, которые приводят к созданию альтернативного формата~--- \verb|zrec| (сокр.~от compressed records).

\section{О пользе сортировки}
Главным просчетом в формате \verb|zchunk| является его общность: он сжимает какие-то куски, которые распаковываются
во что угодно.  Формат \verb|zrec| вместо этого постулирует, что сжимаемые записи упорядочены каким-либо образом (напр.,
естественным образом~--- по имени пакета, но возможна и группировка по \verb|src.rpm|).  Этот постулат имеет далеко
идущие последствия.

Во-первых, в отсортированном списке у записей возникает \textit{локальное сходство}, которое <<не улавливается>> словарем.
Например, пакеты \verb|perl-*| имеют между собой сходство в части зависимостей и т.п.  Значит, группировка соседних
записей при нарезке должна привести к значительному улучшению сжатия.  А библиотека тогда может реализовать
процедуру сжатия с <<прозрачной>> группировкой.

Во-вторых, сортировка меняет требования к сопоставлению кусков.  Это даже две разные математические задачи:
1) чтобы уникально идентифицировать каждый кусок среди всех остальных, требуется 96-битный хеш (при числе кусков порядка $10^5$
и вероятности коллизии порядка $10^{-18}$); 2) чтобы определить, изменился ли кусок, требуется 60 битов хеш-материала
(т.\,к.~$2^{-60}\approx10^{-18}$).  Поэтому можно считать, что когда куски <<расставлены по местам>>, то для идентификации
куска в <<локальной окрестности>> достаточно 64-битного хеша.

\section{Группировка записей}
Группировка записей может заметно, хотя и не радикально, улучшить сжатие.  Возьмем файл \verb|srclist.xz| (1.86 Мб)~--- в разжатом
виде 10 Мб.  <<Солидное>> сжатие \verb|zstd -19| дает 1.97 Мб.  Если сжимать каждую запись по отдельности, получается 5.8 Мб~---
мало избыточности!  Радикальное улучшение дает сжатие записей со словарем~--- 2.44 Мб (словарь 512 Кб, в сжатом виде 177 Кб).
Если теперь еще группировать записи парами, получается 2.26 Мб, по три~--- 2.21 Мб, по четыре~--- 2.18 Мб и далее очень медленно.
В общем, группировка по 2-3 записи улучшает сжатие до 10\%.

Записи однако нельзя группировать в ровных количествах, это приведет к \textit{сдвигу границ} и сделает невозможным синхронизацию.
Так, если из потока записей, сгруппированных парами: \texttt{AB CD EF...} будет удалена запись \verb|B|, то границы пар сдвинутся:
\texttt{AC DE F...} и все куски перестанут совпадать.  Классический подход к решению этой проблемы состоит в том, что нужно
нарезать куски переменной длины псевдослучайным образом, основываясь на данных внутри кусков (content-defined chunking).
А именно, данные сканируются скользящим окном и нарезаются, когда контрольная сумма в окне принимает определенное значение.
Упрощенная реализация такого подхода известна как rsyncable gzip.  Об оптимальной нарезке нарезке см.~статью 2005 г.~\cite{hp}
и свежую работу \cite{xia}.

Наша идея \textit{ультракороткой оптимальной нарезки} состоит в следующем: записи можно сравнивать по их хеш-коду.
Тогда если напр.~$\underline{A<B<C}>\underline{D<E}$, то упорядоченная подпоследовательность и образует группу,
а нарушение порядка дает разрез.  Нарушение порядка можно также вынужденно допустить в первых двух элементах группы.
Это приводит к следующей \textbf{Стратегии}: 1)~Поместить в очередь $A$, $B$ и $C$.  Если $B>C$, отрезать $AB$ (и тогда $C$
становится новым $A$). 2)~Иначе добавить в очередь $D$.  Если $C>D$, отрезать $ABC$.  3)~Иначе отрезать $ABCD$.

Отметим, что хотя на шагах 1) и 2) сравнение одно и то же, вероятность его разная: $\Pr(B<C)=1/2$, а $\Pr(C<D)<1/2$.
И поскольку условие одно и то же, то для преодоления рассинхронизации дается более одной возможности <<зацепиться
за нужное место>>, и в то же время рассинхронизация быстро пресекается.

Отметим также важную \textit{практическую модификацию} процедуры нарезки: для использования в качестве $A, B\ldots$
желательно хешировать не всю запись, а лишь имя пакета (или имя \verb|src.rpm| пакета без версии при группировке по \verb|src.rpm|).
Тогда изменение версии у пакета не приводит к изменению нарезки: изменение оказывается полностью локализованным внутри куска;
к рассинхронизации может привести только удаление и добавление новых пакетов.

Мы взяли файл \verb|srclist.xz| от 1 июня и 1 июля 2018 г.  Без группировки записей для регенерации нового файла
недостает 923 кусков общим объемом 271 Кб, а с описанной группировкой - 809 кусков объемом 568 Кб.  При этом группировка
также уменьшает размер индекса примерно с 80 до 30 Кб, однако в данном случае увеличившийся объем кусков в несколько
раз перекрывает уменьшение индекса.  Видно, что при нерегулярных обновлениях группировка оказывается невыгодной.

\section{Хеширование и расстановка}
\section{О надежности конструкции}

\begin{thebibliography}{9}

\bibitem{zpkglist}
Alexey Tourbin. \verb|zpkglist|~--- Compressed file format\\
\url{https://github.com/svpv/zpkglist}

\bibitem{dieter}
Jonathan Dieter. What is \verb|zchunk|?\\
\url{https://www.jdieter.net/posts/2018/05/31/what-is-zchunk/}

\bibitem{hp}
Kave Eshghi, Hsiu Khuern Tang (2005).
A Framework for Analyzing and Improving Content-Based Chunking Algorithms

\bibitem{xia}
Wen Xia et al. (2016).
FastCDC: a Fast and Efficient Content-Defined Chunking Approach for Data Deduplication

\end{thebibliography}

\end{document}
